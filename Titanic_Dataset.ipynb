{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic_Dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPrqVpa4Iif895Exa5tKPUa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZenoZoldyck/Kaggle_competions/blob/main/Titanic_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BYphmms3u12S",
        "outputId": "85e70412-a952-43d6-d538-e9304511fef2"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOTWxLiQvDZw"
      },
      "source": [
        "# importing datasets\n",
        "\n",
        "train = pd.read_excel(\"/content/train_nn.xlsx\")\n",
        "test = pd.read_csv(\"/content/test_n.csv\")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3k55wQPGxnuC",
        "outputId": "1f223528-4045-4d55-9ce3-a417c73229bf"
      },
      "source": [
        "# viewing the train data\n",
        "train.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
              "0         0       3    male  22.0      1      0   7.2500        S\n",
              "1         1       1  female  38.0      1      0  71.2833        C\n",
              "2         1       3  female  26.0      0      0   7.9250        S\n",
              "3         1       1  female  35.0      1      0  53.1000        S\n",
              "4         0       3    male  35.0      0      0   8.0500        S"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "XnsTzUKrxtm-",
        "outputId": "98b5b629-ecdc-425a-fe86-4c9897c7cc05"
      },
      "source": [
        "test.head(11)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.2250</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.6292</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>29.0000</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2292</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>21.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24.1500</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>30.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.8958</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
              "0        3    male  34.5      0      0   7.8292        Q\n",
              "1        3  female  47.0      1      0   7.0000        S\n",
              "2        2    male  62.0      0      0   9.6875        Q\n",
              "3        3    male  27.0      0      0   8.6625        S\n",
              "4        3  female  22.0      1      1  12.2875        S\n",
              "5        3    male  14.0      0      0   9.2250        S\n",
              "6        3  female  30.0      0      0   7.6292        Q\n",
              "7        2    male  26.0      1      1  29.0000        S\n",
              "8        3  female  18.0      0      0   7.2292        C\n",
              "9        3    male  21.0      2      0  24.1500        S\n",
              "10       3    male  30.3      0      0   7.8958        S"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD6t2VkWxyxw"
      },
      "source": [
        "# time to preprocess the data\n",
        "\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), [\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]),\n",
        "    (OneHotEncoder(handle_unknown = \"ignore\"), [\"Sex\", \"Embarked\"])\n",
        ")\n",
        "\n",
        "X = train.drop([\"Survived\"], axis = 1)\n",
        "y = train[\"Survived\"]\n",
        "\n",
        "ct.fit(X)\n",
        "X = ct.fit_transform(X)\n",
        "test_data = ct.fit_transform(test)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMCrk7RTztnb",
        "outputId": "ef949bf6-52d7-4354-dd30-07784f1f02ba"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.27117366, 0.125     , 0.        , 0.01415106,\n",
              "       0.        , 1.        , 0.        , 0.        , 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oon4AQ0o1tg3"
      },
      "source": [
        "import numpy as np\n",
        "y = np.array(y)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjHxyftN100L",
        "outputId": "52798ff1-2286-46e0-fea9-8b91591c5b12"
      },
      "source": [
        "test_data[0]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.4527232 , 0.        , 0.        , 0.01528158,\n",
              "       0.        , 1.        , 0.        , 1.        , 0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tx_OMqZF4BbF",
        "outputId": "d3c0a06a-8b8b-4c10-9ace-d6828f2bc2a5"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((889, 10), (889,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL5y2gwU6ALG"
      },
      "source": [
        "# creating train and test dataset\n",
        "\n",
        "X_train = X\n",
        "y_train = y"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Fh8yrNe4Ifn",
        "outputId": "91744a22-8ffe-4452-f34a-b82d739395d9"
      },
      "source": [
        "# Time for model creation\n",
        "model_5 = tf.keras.Sequential([\n",
        "   tf.keras.layers.Dense(32, activation = \"relu\"),\n",
        "   tf.keras.layers.Dropout(0.2),\n",
        "   tf.keras.layers.Dense(64, activation = \"relu\"),\n",
        "   tf.keras.layers.Dense(1, activation = \"sigmoid\")                          \n",
        "])\n",
        "model_5.compile(loss = tf.keras.losses.mse,\n",
        "              optimizer = tf.keras.optimizers.Adam(),\n",
        "              metrics = [\"accuracy\"])\n",
        "history = model_5.fit(X_train, y_train, epochs = 400)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "28/28 [==============================] - 0s 971us/step - loss: 0.2185 - accuracy: 0.6828\n",
            "Epoch 2/400\n",
            "28/28 [==============================] - 0s 907us/step - loss: 0.1798 - accuracy: 0.7604\n",
            "Epoch 3/400\n",
            "28/28 [==============================] - 0s 937us/step - loss: 0.1604 - accuracy: 0.7840\n",
            "Epoch 4/400\n",
            "28/28 [==============================] - 0s 968us/step - loss: 0.1529 - accuracy: 0.7840\n",
            "Epoch 5/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.8020\n",
            "Epoch 6/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.7930\n",
            "Epoch 7/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.8043\n",
            "Epoch 8/400\n",
            "28/28 [==============================] - 0s 975us/step - loss: 0.1459 - accuracy: 0.8110\n",
            "Epoch 9/400\n",
            "28/28 [==============================] - 0s 988us/step - loss: 0.1436 - accuracy: 0.8054\n",
            "Epoch 10/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1433 - accuracy: 0.7987\n",
            "Epoch 11/400\n",
            "28/28 [==============================] - 0s 992us/step - loss: 0.1426 - accuracy: 0.8031\n",
            "Epoch 12/400\n",
            "28/28 [==============================] - 0s 996us/step - loss: 0.1404 - accuracy: 0.8144\n",
            "Epoch 13/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.8110\n",
            "Epoch 14/400\n",
            "28/28 [==============================] - 0s 999us/step - loss: 0.1437 - accuracy: 0.8009\n",
            "Epoch 15/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.8065\n",
            "Epoch 16/400\n",
            "28/28 [==============================] - 0s 974us/step - loss: 0.1395 - accuracy: 0.8065\n",
            "Epoch 17/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.8088\n",
            "Epoch 18/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1368 - accuracy: 0.8076\n",
            "Epoch 19/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1395 - accuracy: 0.8099\n",
            "Epoch 20/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.8133\n",
            "Epoch 21/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.8144\n",
            "Epoch 22/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.8200\n",
            "Epoch 23/400\n",
            "28/28 [==============================] - 0s 979us/step - loss: 0.1339 - accuracy: 0.8178\n",
            "Epoch 24/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.8043\n",
            "Epoch 25/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.8110\n",
            "Epoch 26/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.8144\n",
            "Epoch 27/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.8133\n",
            "Epoch 28/400\n",
            "28/28 [==============================] - 0s 984us/step - loss: 0.1344 - accuracy: 0.8121\n",
            "Epoch 29/400\n",
            "28/28 [==============================] - 0s 994us/step - loss: 0.1360 - accuracy: 0.8133\n",
            "Epoch 30/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.8200\n",
            "Epoch 31/400\n",
            "28/28 [==============================] - 0s 999us/step - loss: 0.1326 - accuracy: 0.8178\n",
            "Epoch 32/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.8256\n",
            "Epoch 33/400\n",
            "28/28 [==============================] - 0s 977us/step - loss: 0.1345 - accuracy: 0.8088\n",
            "Epoch 34/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.8121\n",
            "Epoch 35/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.8155\n",
            "Epoch 36/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.8144\n",
            "Epoch 37/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1318 - accuracy: 0.8245\n",
            "Epoch 38/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1317 - accuracy: 0.8200\n",
            "Epoch 39/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1306 - accuracy: 0.8189\n",
            "Epoch 40/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.8121\n",
            "Epoch 41/400\n",
            "28/28 [==============================] - 0s 967us/step - loss: 0.1320 - accuracy: 0.8200\n",
            "Epoch 42/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1323 - accuracy: 0.8211\n",
            "Epoch 43/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1294 - accuracy: 0.8245\n",
            "Epoch 44/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.8245\n",
            "Epoch 45/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.8211\n",
            "Epoch 46/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1299 - accuracy: 0.8234\n",
            "Epoch 47/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.8324\n",
            "Epoch 48/400\n",
            "28/28 [==============================] - 0s 947us/step - loss: 0.1306 - accuracy: 0.8268\n",
            "Epoch 49/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1271 - accuracy: 0.8200\n",
            "Epoch 50/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.8301\n",
            "Epoch 51/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1274 - accuracy: 0.8346\n",
            "Epoch 52/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.8256\n",
            "Epoch 53/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.8290\n",
            "Epoch 54/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1293 - accuracy: 0.8290\n",
            "Epoch 55/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.8313\n",
            "Epoch 56/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.8301\n",
            "Epoch 57/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1311 - accuracy: 0.8290\n",
            "Epoch 58/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.8290\n",
            "Epoch 59/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1299 - accuracy: 0.8223\n",
            "Epoch 60/400\n",
            "28/28 [==============================] - 0s 972us/step - loss: 0.1280 - accuracy: 0.8290\n",
            "Epoch 61/400\n",
            "28/28 [==============================] - 0s 989us/step - loss: 0.1264 - accuracy: 0.8234\n",
            "Epoch 62/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.8313\n",
            "Epoch 63/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.8324\n",
            "Epoch 64/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1249 - accuracy: 0.8369\n",
            "Epoch 65/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1299 - accuracy: 0.8279\n",
            "Epoch 66/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.8268\n",
            "Epoch 67/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.8301\n",
            "Epoch 68/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.8290\n",
            "Epoch 69/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.8380\n",
            "Epoch 70/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.8245\n",
            "Epoch 71/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.8256\n",
            "Epoch 72/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.8369\n",
            "Epoch 73/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.8234\n",
            "Epoch 74/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.8290\n",
            "Epoch 75/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1275 - accuracy: 0.8313\n",
            "Epoch 76/400\n",
            "28/28 [==============================] - 0s 989us/step - loss: 0.1224 - accuracy: 0.8346\n",
            "Epoch 77/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.8380\n",
            "Epoch 78/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1263 - accuracy: 0.8369\n",
            "Epoch 79/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.8358\n",
            "Epoch 80/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.8358\n",
            "Epoch 81/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1258 - accuracy: 0.8335\n",
            "Epoch 82/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.8425\n",
            "Epoch 83/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1248 - accuracy: 0.8391\n",
            "Epoch 84/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.8391\n",
            "Epoch 85/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.8369\n",
            "Epoch 86/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.8369\n",
            "Epoch 87/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1238 - accuracy: 0.8335\n",
            "Epoch 88/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.8414\n",
            "Epoch 89/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.8313\n",
            "Epoch 90/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1277 - accuracy: 0.8324\n",
            "Epoch 91/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1218 - accuracy: 0.8358\n",
            "Epoch 92/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.8358\n",
            "Epoch 93/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1225 - accuracy: 0.8436\n",
            "Epoch 94/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.8358\n",
            "Epoch 95/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1248 - accuracy: 0.8324\n",
            "Epoch 96/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.8324\n",
            "Epoch 97/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.8380\n",
            "Epoch 98/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1218 - accuracy: 0.8358\n",
            "Epoch 99/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.8346\n",
            "Epoch 100/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.8369\n",
            "Epoch 101/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1238 - accuracy: 0.8324\n",
            "Epoch 102/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1243 - accuracy: 0.8313\n",
            "Epoch 103/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1238 - accuracy: 0.8313\n",
            "Epoch 104/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.8391\n",
            "Epoch 105/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1231 - accuracy: 0.8358\n",
            "Epoch 106/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.8369\n",
            "Epoch 107/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.8403\n",
            "Epoch 108/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.8301\n",
            "Epoch 109/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.8425\n",
            "Epoch 110/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.8414\n",
            "Epoch 111/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.8425\n",
            "Epoch 112/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.8346\n",
            "Epoch 113/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1225 - accuracy: 0.8346\n",
            "Epoch 114/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.8346\n",
            "Epoch 115/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.8335\n",
            "Epoch 116/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.8358\n",
            "Epoch 117/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.8436\n",
            "Epoch 118/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.8358\n",
            "Epoch 119/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.8414\n",
            "Epoch 120/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1229 - accuracy: 0.8414\n",
            "Epoch 121/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.8358\n",
            "Epoch 122/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1195 - accuracy: 0.8369\n",
            "Epoch 123/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.8391\n",
            "Epoch 124/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.8403\n",
            "Epoch 125/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.8324\n",
            "Epoch 126/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.8346\n",
            "Epoch 127/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.8358\n",
            "Epoch 128/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1214 - accuracy: 0.8380\n",
            "Epoch 129/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.8358\n",
            "Epoch 130/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.8346\n",
            "Epoch 131/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.8369\n",
            "Epoch 132/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.8324\n",
            "Epoch 133/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.8369\n",
            "Epoch 134/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.8301\n",
            "Epoch 135/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1185 - accuracy: 0.8425\n",
            "Epoch 136/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.8324\n",
            "Epoch 137/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1225 - accuracy: 0.8313\n",
            "Epoch 138/400\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.8436\n",
            "Epoch 139/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.8391\n",
            "Epoch 140/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1231 - accuracy: 0.8358\n",
            "Epoch 141/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1226 - accuracy: 0.8369\n",
            "Epoch 142/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1195 - accuracy: 0.8425\n",
            "Epoch 143/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.8414\n",
            "Epoch 144/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.8470\n",
            "Epoch 145/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.8470\n",
            "Epoch 146/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.8459\n",
            "Epoch 147/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.8403\n",
            "Epoch 148/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1205 - accuracy: 0.8380\n",
            "Epoch 149/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.8369\n",
            "Epoch 150/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.8324\n",
            "Epoch 151/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.8436\n",
            "Epoch 152/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.8436\n",
            "Epoch 153/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1196 - accuracy: 0.8436\n",
            "Epoch 154/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.8346\n",
            "Epoch 155/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.8425\n",
            "Epoch 156/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.8425\n",
            "Epoch 157/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1182 - accuracy: 0.8470\n",
            "Epoch 158/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.8459\n",
            "Epoch 159/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.8425\n",
            "Epoch 160/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.8414\n",
            "Epoch 161/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.8391\n",
            "Epoch 162/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.8335\n",
            "Epoch 163/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.8391\n",
            "Epoch 164/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.8504\n",
            "Epoch 165/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1196 - accuracy: 0.8380\n",
            "Epoch 166/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.8414\n",
            "Epoch 167/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1187 - accuracy: 0.8436\n",
            "Epoch 168/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.8425\n",
            "Epoch 169/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.8436\n",
            "Epoch 170/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.8380\n",
            "Epoch 171/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.8391\n",
            "Epoch 172/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.8391\n",
            "Epoch 173/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.8380\n",
            "Epoch 174/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1177 - accuracy: 0.8459\n",
            "Epoch 175/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.8493\n",
            "Epoch 176/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.8481\n",
            "Epoch 177/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.8481\n",
            "Epoch 178/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.8391\n",
            "Epoch 179/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.8448\n",
            "Epoch 180/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.8380\n",
            "Epoch 181/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.8391\n",
            "Epoch 182/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.8436\n",
            "Epoch 183/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1195 - accuracy: 0.8414\n",
            "Epoch 184/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1185 - accuracy: 0.8391\n",
            "Epoch 185/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.8403\n",
            "Epoch 186/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.8470\n",
            "Epoch 187/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.8414\n",
            "Epoch 188/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.8403\n",
            "Epoch 189/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.8448\n",
            "Epoch 190/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.8459\n",
            "Epoch 191/400\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.8403\n",
            "Epoch 192/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.8425\n",
            "Epoch 193/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.8380\n",
            "Epoch 194/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.8369\n",
            "Epoch 195/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.8425\n",
            "Epoch 196/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.8448\n",
            "Epoch 197/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1177 - accuracy: 0.8481\n",
            "Epoch 198/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1166 - accuracy: 0.8448\n",
            "Epoch 199/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.8493\n",
            "Epoch 200/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.8335\n",
            "Epoch 201/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.8403\n",
            "Epoch 202/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.8414\n",
            "Epoch 203/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.8448\n",
            "Epoch 204/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.8425\n",
            "Epoch 205/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.8436\n",
            "Epoch 206/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.8436\n",
            "Epoch 207/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.8414\n",
            "Epoch 208/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.8425\n",
            "Epoch 209/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.8538\n",
            "Epoch 210/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1166 - accuracy: 0.8515\n",
            "Epoch 211/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.8459\n",
            "Epoch 212/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.8470\n",
            "Epoch 213/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.8504\n",
            "Epoch 214/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.8425\n",
            "Epoch 215/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.8391\n",
            "Epoch 216/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.8493\n",
            "Epoch 217/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.8369\n",
            "Epoch 218/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.8504\n",
            "Epoch 219/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.8459\n",
            "Epoch 220/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1166 - accuracy: 0.8448\n",
            "Epoch 221/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.8380\n",
            "Epoch 222/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.8391\n",
            "Epoch 223/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.8470\n",
            "Epoch 224/400\n",
            "28/28 [==============================] - 0s 973us/step - loss: 0.1146 - accuracy: 0.8470\n",
            "Epoch 225/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.8515\n",
            "Epoch 226/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.8481\n",
            "Epoch 227/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.8414\n",
            "Epoch 228/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.8403\n",
            "Epoch 229/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.8504\n",
            "Epoch 230/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.8436\n",
            "Epoch 231/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.8470\n",
            "Epoch 232/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.8493\n",
            "Epoch 233/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.8380\n",
            "Epoch 234/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.8391\n",
            "Epoch 235/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.8335\n",
            "Epoch 236/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.8526\n",
            "Epoch 237/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1182 - accuracy: 0.8369\n",
            "Epoch 238/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.8470\n",
            "Epoch 239/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.8459\n",
            "Epoch 240/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.8504\n",
            "Epoch 241/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.8436\n",
            "Epoch 242/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.8448\n",
            "Epoch 243/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.8481\n",
            "Epoch 244/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.8493\n",
            "Epoch 245/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1182 - accuracy: 0.8358\n",
            "Epoch 246/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.8403\n",
            "Epoch 247/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.8448\n",
            "Epoch 248/400\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1169 - accuracy: 0.8425\n",
            "Epoch 249/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.8380\n",
            "Epoch 250/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.8481\n",
            "Epoch 251/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.8459\n",
            "Epoch 252/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.8459\n",
            "Epoch 253/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.8425\n",
            "Epoch 254/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1166 - accuracy: 0.8459\n",
            "Epoch 255/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.8425\n",
            "Epoch 256/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.8448\n",
            "Epoch 257/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.8436\n",
            "Epoch 258/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.8504\n",
            "Epoch 259/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1166 - accuracy: 0.8448\n",
            "Epoch 260/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.8448\n",
            "Epoch 261/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.8414\n",
            "Epoch 262/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.8481\n",
            "Epoch 263/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.8448\n",
            "Epoch 264/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.8470\n",
            "Epoch 265/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.8515\n",
            "Epoch 266/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.8470\n",
            "Epoch 267/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.8493\n",
            "Epoch 268/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.8538\n",
            "Epoch 269/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.8481\n",
            "Epoch 270/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.8358\n",
            "Epoch 271/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1142 - accuracy: 0.8459\n",
            "Epoch 272/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.8459\n",
            "Epoch 273/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.8436\n",
            "Epoch 274/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.8526\n",
            "Epoch 275/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.8594\n",
            "Epoch 276/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1173 - accuracy: 0.8414\n",
            "Epoch 277/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.8414\n",
            "Epoch 278/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.8493\n",
            "Epoch 279/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.8448\n",
            "Epoch 280/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.8470\n",
            "Epoch 281/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1142 - accuracy: 0.8538\n",
            "Epoch 282/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.8470\n",
            "Epoch 283/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.8391\n",
            "Epoch 284/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.8504\n",
            "Epoch 285/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.8403\n",
            "Epoch 286/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.8414\n",
            "Epoch 287/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.8515\n",
            "Epoch 288/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.8459\n",
            "Epoch 289/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.8436\n",
            "Epoch 290/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.8515\n",
            "Epoch 291/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.8448\n",
            "Epoch 292/400\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1148 - accuracy: 0.8459\n",
            "Epoch 293/400\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.8403\n",
            "Epoch 294/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.8380\n",
            "Epoch 295/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.8538\n",
            "Epoch 296/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1156 - accuracy: 0.8459\n",
            "Epoch 297/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.8493\n",
            "Epoch 298/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.8391\n",
            "Epoch 299/400\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1131 - accuracy: 0.8504\n",
            "Epoch 300/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.8481\n",
            "Epoch 301/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1133 - accuracy: 0.8493\n",
            "Epoch 302/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.8526\n",
            "Epoch 303/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.8481\n",
            "Epoch 304/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.8493\n",
            "Epoch 305/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.8560\n",
            "Epoch 306/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.8448\n",
            "Epoch 307/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.8493\n",
            "Epoch 308/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.8538\n",
            "Epoch 309/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.8470\n",
            "Epoch 310/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.8504\n",
            "Epoch 311/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.8481\n",
            "Epoch 312/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.8549\n",
            "Epoch 313/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.8481\n",
            "Epoch 314/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.8583\n",
            "Epoch 315/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.8594\n",
            "Epoch 316/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1156 - accuracy: 0.8436\n",
            "Epoch 317/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.8470\n",
            "Epoch 318/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.8470\n",
            "Epoch 319/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.8493\n",
            "Epoch 320/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.8515\n",
            "Epoch 321/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.8549\n",
            "Epoch 322/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.8436\n",
            "Epoch 323/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.8470\n",
            "Epoch 324/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.8493\n",
            "Epoch 325/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.8414\n",
            "Epoch 326/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.8583\n",
            "Epoch 327/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.8504\n",
            "Epoch 328/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.8448\n",
            "Epoch 329/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.8549\n",
            "Epoch 330/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.8493\n",
            "Epoch 331/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.8459\n",
            "Epoch 332/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.8481\n",
            "Epoch 333/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.8448\n",
            "Epoch 334/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.8526\n",
            "Epoch 335/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.8526\n",
            "Epoch 336/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.8448\n",
            "Epoch 337/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.8448\n",
            "Epoch 338/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.8470\n",
            "Epoch 339/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.8481\n",
            "Epoch 340/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.8515\n",
            "Epoch 341/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.8504\n",
            "Epoch 342/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.8459\n",
            "Epoch 343/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.8549\n",
            "Epoch 344/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.8526\n",
            "Epoch 345/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.8515\n",
            "Epoch 346/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.8493\n",
            "Epoch 347/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.8504\n",
            "Epoch 348/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.8549\n",
            "Epoch 349/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.8504\n",
            "Epoch 350/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.8538\n",
            "Epoch 351/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.8560\n",
            "Epoch 352/400\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.8414\n",
            "Epoch 353/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.8493\n",
            "Epoch 354/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.8526\n",
            "Epoch 355/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.8560\n",
            "Epoch 356/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.8515\n",
            "Epoch 357/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.8481\n",
            "Epoch 358/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.8571\n",
            "Epoch 359/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.8526\n",
            "Epoch 360/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.8538\n",
            "Epoch 361/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.8459\n",
            "Epoch 362/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.8526\n",
            "Epoch 363/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.8526\n",
            "Epoch 364/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.8481\n",
            "Epoch 365/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.8504\n",
            "Epoch 366/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.8504\n",
            "Epoch 367/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.8526\n",
            "Epoch 368/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1133 - accuracy: 0.8481\n",
            "Epoch 369/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.8538\n",
            "Epoch 370/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.8639\n",
            "Epoch 371/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.8425\n",
            "Epoch 372/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1126 - accuracy: 0.8583\n",
            "Epoch 373/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.8481\n",
            "Epoch 374/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 0.8504\n",
            "Epoch 375/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.8515\n",
            "Epoch 376/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.8526\n",
            "Epoch 377/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.8526\n",
            "Epoch 378/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.8504\n",
            "Epoch 379/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.8515\n",
            "Epoch 380/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.8526\n",
            "Epoch 381/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.8526\n",
            "Epoch 382/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1133 - accuracy: 0.8481\n",
            "Epoch 383/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.8481\n",
            "Epoch 384/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.8560\n",
            "Epoch 385/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.8493\n",
            "Epoch 386/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.8560\n",
            "Epoch 387/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.8515\n",
            "Epoch 388/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.8504\n",
            "Epoch 389/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.8515\n",
            "Epoch 390/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.8414\n",
            "Epoch 391/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.8493\n",
            "Epoch 392/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.8448\n",
            "Epoch 393/400\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1133 - accuracy: 0.8448\n",
            "Epoch 394/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.8639\n",
            "Epoch 395/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.8504\n",
            "Epoch 396/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.8526\n",
            "Epoch 397/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.8549\n",
            "Epoch 398/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.8594\n",
            "Epoch 399/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.8504\n",
            "Epoch 400/400\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.8549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "gmRGqfQm6xIt",
        "outputId": "fd1253a3-118e-4cee-caad-8cf675d33abd"
      },
      "source": [
        "pd.DataFrame(history.history).plot()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd4ddeae0d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpV-5lv58--T",
        "outputId": "d252f5d1-7ccc-4ffe-e218-a599737edcc3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_27 (Dense)             (None, 32)                352       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,441\n",
            "Trainable params: 1,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqtBTkTQ_4Wq"
      },
      "source": [
        "y_preds = model.predict(test_data)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE5-ZOf_ATb3",
        "outputId": "340075fb-5261-4907-f974-8721de8803d5"
      },
      "source": [
        "y_preds[10]"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.0957014], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipKoR4cHABAm",
        "outputId": "206fcac6-2e61-4231-990e-a32f9785228e"
      },
      "source": [
        "y_val = y_preds.round()\n",
        "len(y_val)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "418"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L2avs_iK1Rk"
      },
      "source": [
        "abc = pd.DataFrame(y_val)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2xSc0i7OE6r"
      },
      "source": [
        "abc.to_csv(\"here_we_go.csv\")"
      ],
      "execution_count": 82,
      "outputs": []
    }
  ]
}